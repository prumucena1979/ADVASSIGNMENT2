{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d42eec",
   "metadata": {},
   "source": [
    "** Business Challenge 1: Application of Customer Sentiment Analysis on Yelp Dataset **\n",
    "Yelp is an online platform where people can rate, review, and share experiences about local\n",
    "businesses. Customer reviews contain valuable insights into customer satisfaction, product\n",
    "quality, and service delivery. However, the massive volume makes it impossible for\n",
    "managers to manually read and interpret all reviews. The company is therefore exploring\n",
    "automated sentiment analysis to understand customer opinions at scale and make datadriven decisions that improve service quality and competitiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbabd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install datasets\n",
    "#%pip install transformers torch\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "print(dataset)\n",
    "# 'dataset' is a DatasetDict (not callable). Access splits like this:\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ( add more if needed )\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04775bb",
   "metadata": {},
   "source": [
    "Task I: Understanding Customer Feedback (Exploratory Analysis)\n",
    "Before building models, the analytics team must understand the structure of customer\n",
    "feedback:\n",
    "1. Assess whether there is a class imbalance (e.g., more positive reviews than\n",
    "negative).\n",
    "2. Extract and display sample reviews from both positive and negative categories to\n",
    "illustrate customer voice.\n",
    "3. Plot the distribution of review lengths to evaluate typical review detail and prepare\n",
    "for model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and preprocess\n",
    "print(dataset)\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "#1.1 - Distribution of classes in training set.\n",
    "# Calculate value counts for the 'label' column\n",
    "label_counts = train_df['label'].value_counts()\n",
    "\n",
    "print(\"--- Class Distribution in Training Set ---\")\n",
    "print(label_counts)\n",
    "\n",
    "# Calculate percentages\n",
    "total_samples = len(train_df)\n",
    "percent_0 = (label_counts[0] / total_samples) * 100\n",
    "percent_1 = (label_counts[1] / total_samples) * 100\n",
    "\n",
    "print(f\"\\nPercentage of Negative (0) reviews: {percent_0:.2f}%\")\n",
    "print(f\"Percentage of Positive (1) reviews: {percent_1:.2f}%\")\n",
    "\n",
    "# Visualization of Class Distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=[\"red\", \"green\"])\n",
    "plt.title('Distribution of Yelp Review Sentiment Classes ')\n",
    "plt.xlabel('Sentiment Label (0: Negative, 1: Positive)')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 - Extract and display sample reviews from both positive and negative categories to illustrate customer voice\n",
    "# Get sample negative reviews (Label 0)\n",
    "negative_samples = train_df[train_df['label'] == 0]['text'].head(3)\n",
    "\n",
    "# Get sample positive reviews (Label 1)\n",
    "positive_samples = train_df[train_df['label'] == 1]['text'].head(3)\n",
    "\n",
    "print(\"--- Sample Negative Reviews (Label 0) ---\")\n",
    "for i, review in enumerate(negative_samples):\n",
    "    print(f\"Review {i+1}:\\n{review}\\n---\")\n",
    "\n",
    "print(\"\\n--- Sample Positive Reviews (Label 1) ---\")\n",
    "for i, review in enumerate(positive_samples):\n",
    "    print(f\"Review {i+1}:\\n{review}\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 plot the distribution of review lengths for both positive and negative reviews.\n",
    "\n",
    "# Create a new column for review length\n",
    "train_df['review_length'] = train_df['text'].apply(len)\n",
    "\n",
    "# Plot the distribution of review lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['review_length'], bins=50, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Yelp Review Lengths (in characters) ')\n",
    "plt.xlabel('Review Length (Characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 1000) # Limit x-axis for better visibility of the bulk of the data\n",
    "plt.show()\n",
    "\n",
    "# Calculate descriptive statistics for review lengths\n",
    "print(\"\\n--- Descriptive Statistics for Review Lengths ---\")\n",
    "print(train_df['review_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d51e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Plot of Review Lengths by Sentiment\n",
    "# --- Code for the Comparison Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the distribution for Negative Reviews (Label 0)\n",
    "sns.kdeplot(\n",
    "    train_df[train_df['label'] == 0]['review_length'],\n",
    "    label='Negative (0)',\n",
    "    color='red',\n",
    "    fill=True,\n",
    "    alpha=0.4,\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Plot the distribution for Positive Reviews (Label 1)\n",
    "sns.kdeplot(\n",
    "    train_df[train_df['label'] == 1]['review_length'],\n",
    "    label='Positive (1)',\n",
    "    color='green',\n",
    "    fill=True,\n",
    "    alpha=0.4,\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Review Lengths: Positive vs. Negative')\n",
    "plt.xlabel('Review Length (Characters)')\n",
    "plt.ylabel('Density')\n",
    "# Based on your statistics (75% is 947), limiting to 1000 is still appropriate\n",
    "plt.xlim(0, 1000) \n",
    "plt.legend()\n",
    "plt.show() # Crucial command to display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba822c4d",
   "metadata": {},
   "source": [
    "TASK 2 - The company wants an initial benchmark model to classify reviews as positive or\n",
    "negative.\n",
    "1. Develop a baseline sentiment classifier using TF-IDF + Random Forest.\n",
    "2. Provide a validation report on a validation partition of the training set showing\n",
    "precision, recall, F1-score, and support to assess strengths and weaknesses of the\n",
    "baseline model.\n",
    "3. Display a confusion matrix on the validation data to illustrate misclassifications.\n",
    "4. Use grid search optimization to improve the baseline by tuning:\n",
    "o Number of estimators [100, 500]\n",
    "o Maximum tree depth [None, 20, 50]\n",
    "o Minimum samples split [2, 5]\n",
    "o Minimum samples per leaf [2, 4]\n",
    "o Maximum features at each node [\"sqrt\", \"log2\"]\n",
    "5. Report the best model parameters and explain why they are important for business\n",
    "decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20cec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 - Develop a Baseline Sentiment Classifier (TF-IDF + Random Forest)\n",
    "# Use a smaller subset of the training data for faster processing\n",
    "# Using 50,000 samples for train/validation split\n",
    "SUBSET_SIZE = 5000 #50000\n",
    "subset_df = train_df.head(SUBSET_SIZE)\n",
    "\n",
    "X = subset_df['text']\n",
    "y = subset_df['label']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "\n",
    "# 1. TF-IDF Vectorization\n",
    "# Use up to 10,000 most frequent words/n-grams\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "# 2. Random Forest Classifier (Baseline)\n",
    "# Use default parameters for the baseline\n",
    "rf_baseline = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_baseline.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_baseline = rf_baseline.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model Validation Report (TF-IDF + Random Forest)\n",
    "print(\"\\n--- Baseline Model Validation Report (TF-IDF + Random Forest) ---\")\n",
    "print(classification_report(y_val, y_pred_baseline, target_names=['Negative (0)', 'Positive (1)']))\n",
    "\n",
    "# Display Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred_baseline)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative (0)', 'Positive (1)'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Baseline Random Forest Model ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the model using Grid Search CV\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50], #[100, 500],\n",
    "    'max_depth': [None, 20, 50],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with a smaller, more optimized search space\n",
    "# Using a subset of the training data (X_train_tfidf, y_train)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1), # n_jobs=-1 for parallel processing\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1', # Optimize for F1-score\n",
    "    cv=3,        # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search (This can take several minutes)\n",
    "print(\"\\n--- Starting Grid Search Optimization (This may take time) ---\")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c566272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Best Random Forest Hyperparameters (Grid Search) ---\")\n",
    "print(best_params)\n",
    "print(f\"Best Cross-Validation F1 Score: {best_score:.4f}\")\n",
    "\n",
    "# Train the best model and evaluate on the validation set\n",
    "rf_optimized = grid_search.best_estimator_\n",
    "y_pred_optimized = rf_optimized.predict(X_val_tfidf)\n",
    "\n",
    "print(\"\\n--- Optimized Model Validation Report ---\")\n",
    "print(classification_report(y_val, y_pred_optimized, target_names=['Negative (0)', 'Positive (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Confusion Matrix for Optimized Model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Get the best performing model from Grid Search\n",
    "rf_optimized = grid_search.best_estimator_\n",
    "\n",
    "# 2. Predict on the validation set using the optimized model\n",
    "# X_val_tfidf is the validation data transformed by the TF-IDF vectorizer\n",
    "y_pred_optimized = rf_optimized.predict(X_val_tfidf)\n",
    "\n",
    "# 3. Calculate the Confusion Matrix\n",
    "# y_val is the true sentiment labels for the validation set\n",
    "cm_optimized = confusion_matrix(y_val, y_pred_optimized)\n",
    "\n",
    "# 4. Display the Confusion Matrix\n",
    "plt.figure(figsize=(7, 7))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_optimized,\n",
    "    display_labels=['Negative (0)', 'Positive (1)']\n",
    ")\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Confusion Matrix for Optimized Random Forest Model ')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# 5. Print the Classification Report for a detailed view\n",
    "print(\"\\n--- Optimized Random Forest Model Validation Report ---\")\n",
    "print(classification_report(y_val, y_pred_optimized, target_names=['Negative (0)', 'Positive (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea82c0",
   "metadata": {},
   "source": [
    "Task III: Advanced Sentiment Intelligence with Pretrained Models\n",
    "The company’s leadership is interested in how cutting-edge AI could outperform the\n",
    "baseline.\n",
    "1. Implement two transformer-based pretrained models (from Hugging Face) for\n",
    "sentiment classification and discuss why you selected each model.\n",
    "2. Compare their performance against each other and against the optimized Random\n",
    "Forest model.\n",
    "3. Quantify how much better the transformer models are and explain the business\n",
    "impact (e.g., fewer false negatives could prevent overlooking unhappy customers,\n",
    "better precision could reduce escalation costs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43729624",
   "metadata": {},
   "source": [
    "Model\tJustification\n",
    "1. bert-base-uncased (Base Model)\tIndustry Standard Baseline: BERT is the foundational transformer model. It's a great choice for a first advanced benchmark, as its architecture is well-understood, and it provides a strong performance baseline before moving to larger or more specialized models.\n",
    "2. roberta-base (Improved Model)\tPerformance Leader: RoBERTa (Robustly Optimized BERT Pretraining Approach) is an optimized version of BERT. It was trained longer, on more data, and with different pre-training objectives (dynamic masking), often leading to better performance on downstream tasks like sentiment classification. This showcases the benefit of using state-of-the-art techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490589f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U transformers==4.35.2 torch accelerate\n",
    "#!pip install -U \"transformers\" \"huggingface_hub\"\n",
    "import transformers, huggingface_hub\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(\"huggingface_hub version:\", huggingface_hub.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Define the Model Checkpoints (from Hugging Face Hub)\n",
    "ROBERTA_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "DISTILBERT_MODEL = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# 1. Load RoBERTa (High Performance Model)\n",
    "print(f\"Loading RoBERTa: {ROBERTA_MODEL}...\")\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(ROBERTA_MODEL)\n",
    "model_roberta = AutoModelForSequenceClassification.from_pretrained(ROBERTA_MODEL)\n",
    "print(\"✅ RoBERTa model loaded successfully!\")\n",
    "\n",
    "# 2. Load DistilBERT (High Efficiency Model)\n",
    "print(f\"\\nLoading DistilBERT: {DISTILBERT_MODEL}...\")\n",
    "tokenizer_distilbert = AutoTokenizer.from_pretrained(DISTILBERT_MODEL)\n",
    "model_distilbert = AutoModelForSequenceClassification.from_pretrained(DISTILBERT_MODEL)\n",
    "print(\"✅ DistilBERT model loaded successfully!\")\n",
    "\n",
    "# Final check: Print the type of one loaded model\n",
    "print(f\"\\nLoaded RoBERTa object type: {type(model_roberta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543acd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_roberta.to(device)\n",
    "model_distilbert.to(device)\n",
    "\n",
    "def predict_with_roberta(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Usa cardiffnlp/twitter-roberta-base-sentiment.\n",
    "    Labels típicos: 0=negative, 1=neutral, 2=positive.\n",
    "    Vamos mapear para binário: 0=negativo, 1=positivo (neutro vai pro lado positivo ou você pode escolher outra estratégia).\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "\n",
    "    model_roberta.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "            encoded = tokenizer_roberta(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model_roberta(**encoded)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()  # 0, 1, 2\n",
    "\n",
    "            # Mapear: 0=neg, 1=neutral, 2=pos  →  binário\n",
    "            bin_preds = np.where(preds == 0, 0, 1)  # tudo que não é 0 vira positivo\n",
    "            all_preds.extend(bin_preds)\n",
    "\n",
    "    return np.array(all_preds)\n",
    "\n",
    "\n",
    "def predict_with_distilbert(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Usa distilbert/distilbert-base-uncased-finetuned-sst-2-english.\n",
    "    Labels típicos: 0=NEGATIVE, 1=POSITIVE.\n",
    "    Já está em binário, então mapeamos direto.\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "\n",
    "    model_distilbert.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "            encoded = tokenizer_distilbert(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model_distilbert(**encoded)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()  # 0/1\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    return np.array(all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch # Already loaded, but good practice to keep here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7664f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the Validation Data for Transformer Comparison\n",
    "# Make sure Task II cells (train/validation split + optimized RF) have been run.\n",
    "\n",
    "df_validation = pd.DataFrame({\n",
    "    \"text\": X_val.reset_index(drop=True),\n",
    "    \"label\": y_val.reset_index(drop=True),\n",
    "})\n",
    "\n",
    "# 2. Attach the Optimized Random Forest Predictions (Baseline)\n",
    "# We already computed y_pred_optimized in Task II:\n",
    "#   y_pred_optimized = rf_optimized.predict(X_val_tfidf)\n",
    "\n",
    "df_validation[\"rf_prediction\"] = y_pred_optimized\n",
    "\n",
    "print(f\"Validation DataFrame ready with {len(df_validation)} samples.\")\n",
    "print(\"Baseline RF predictions (rf_prediction) are included.\")\n",
    "df_validation.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b1649",
   "metadata": {},
   "source": [
    "Business Challenge 2: Books recommendation system development\n",
    "Digital book platform (similar to Goodreads or Amazon Kindle) always faces the business\n",
    "challenge of how identify similar books from as well as how books can be recommended to\n",
    "readers that they are most likely to enjoy, based on their past ratings and the behavior of\n",
    "other users.\n",
    "The Goodbooks-10k dataset available in this link, is a popular dataset used for\n",
    "benchmarking recommender systems. The dataset contains customer rating on thousands\n",
    "of books. The file dataset can be briefly described as follows:\n",
    "• user_id: An anonymized identifier for each reader.\n",
    "• book_id: An identifier for each book in the collection (covering 10,000 unique\n",
    "books).\n",
    "• rating: A rating given by the user to the book, ranging from 1 (lowest) to 5 (highest).\n",
    "• Over 6 million ratings provided by more than 50,000 users.\n",
    "• Most users have rated only a handful of books, and most books are rated by only a\n",
    "subset of users.\n",
    "Using this dataset conduct recommendation system analysis by following the tasks\n",
    "given below\n",
    "Task I: Exploratory Data Analysis (EDA)\n",
    "Perform exploratory data analysis on the provided dataset.\n",
    "- Summarize the dataset: number of rows, columns, and types of variables.\n",
    "- Show the distribution of labels or ratings.\n",
    "- Provide at least two visualizations (e.g., histogram, bar chart, word cloud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545a141",
   "metadata": {},
   "source": [
    "## ⚠️ Important: Implicit Library Installation\n",
    "\n",
    "**Requirement:** The `implicit` library is required for this recommendation system.\n",
    "\n",
    "**Installation Note:** The `implicit` library requires C++ compilation, which needs Microsoft Visual C++ Build Tools.\n",
    "\n",
    "**Installation Steps:**\n",
    "- See `INSTALL_IMPLICIT_GUIDE.md` for detailed installation instructions\n",
    "- Estimated time: 30-60 minutes\n",
    "- Disk space: 6-7 GB for build tools\n",
    "- Once installed, the ALS algorithm provides state-of-the-art collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# BUSINESS CHALLENGE 2: BOOK RECOMMENDATION SYSTEM\n",
    "# ============================================\n",
    "# Using Implicit Library for ALS-based Collaborative Filtering\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")\n",
    "print(\"   Using: implicit.als.AlternatingLeastSquares\")\n",
    "print(\"\\nNote: See INSTALL_IMPLICIT_GUIDE.md for library installation instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TASK I: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK I: EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Goodbooks-10k dataset\n",
    "print(\"\\nLoading Goodbooks-10k dataset...\")\n",
    "ratings_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv\"\n",
    "\n",
    "try:\n",
    "    ratings_df = pd.read_csv(ratings_url)\n",
    "    print(f\"✅ Successfully loaded {len(ratings_df):,} ratings\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n--- Dataset Overview ---\")\n",
    "print(f\"Shape: {ratings_df.shape}\")\n",
    "print(f\"Columns: {list(ratings_df.columns)}\")\n",
    "print(f\"\\nData types:\\n{ratings_df.dtypes}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TASK I: DATA SUMMARY AND VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n--- Dataset Summary Statistics ---\")\n",
    "print(f\"Unique users: {ratings_df['user_id'].nunique():,}\")\n",
    "print(f\"Unique books: {ratings_df['book_id'].nunique():,}\")\n",
    "print(f\"Rating range: {ratings_df['rating'].min()} to {ratings_df['rating'].max()}\")\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(ratings_df['rating'].value_counts().sort_index())\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Rating Distribution (Bar)\n",
    "rating_counts = ratings_df['rating'].value_counts().sort_index()\n",
    "axes[0, 0].bar(rating_counts.index, rating_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Rating', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Distribution of Ratings', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Rating Distribution (Pie)\n",
    "colors = ['#ff9999', '#ffcc99', '#ffff99', '#99ff99', '#99ccff']\n",
    "axes[0, 1].pie(rating_counts.values, labels=rating_counts.index, autopct='%1.1f%%',\n",
    "               colors=colors, startangle=90)\n",
    "axes[0, 1].set_title('Rating Distribution (Percentage)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 3: User Activity (log scale)\n",
    "user_ratings = ratings_df.groupby('user_id').size()\n",
    "axes[1, 0].hist(user_ratings, bins=50, color='coral', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Number of Ratings per User', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('User Activity Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Book Popularity\n",
    "book_ratings = ratings_df.groupby('book_id').size()\n",
    "axes[1, 1].hist(book_ratings, bins=50, color='lightgreen', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Number of Ratings per Book', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Book Popularity Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ EDA visualizations complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATA FILTERING FOR QUALITY RECOMMENDATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n--- Filtering Data for Model Training ---\")\n",
    "print(f\"Original dataset: {len(ratings_df):,} ratings\")\n",
    "\n",
    "# Filter users with at least 50 ratings\n",
    "user_counts = ratings_df['user_id'].value_counts()\n",
    "active_users = user_counts[user_counts >= 50].index\n",
    "ratings_filtered = ratings_df[ratings_df['user_id'].isin(active_users)]\n",
    "\n",
    "print(f\"After filtering users (≥50 ratings): {len(ratings_filtered):,} ratings\")\n",
    "\n",
    "# Filter books with at least 50 ratings\n",
    "book_counts = ratings_filtered['book_id'].value_counts()\n",
    "popular_books = book_counts[book_counts >= 50].index\n",
    "ratings_filtered = ratings_filtered[ratings_filtered['book_id'].isin(popular_books)]\n",
    "\n",
    "print(f\"After filtering books (≥50 ratings): {len(ratings_filtered):,} ratings\")\n",
    "print(f\"\\nFiltered dataset statistics:\")\n",
    "print(f\"  Active users: {ratings_filtered['user_id'].nunique():,}\")\n",
    "print(f\"  Popular books: {ratings_filtered['book_id'].nunique():,}\")\n",
    "print(f\"  Sparsity: {(1 - len(ratings_filtered) / (ratings_filtered['user_id'].nunique() * ratings_filtered['book_id'].nunique())) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MATRIX PREPARATION FOR ALS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n--- Preparing User-Item Matrix ---\")\n",
    "\n",
    "# Create ID mappings (original IDs to contiguous indices)\n",
    "user_ids = ratings_filtered['user_id'].unique()\n",
    "book_ids = ratings_filtered['book_id'].unique()\n",
    "\n",
    "user_id_to_index = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "book_id_to_index = {bid: idx for idx, bid in enumerate(book_ids)}\n",
    "index_to_user_id = {idx: uid for uid, idx in user_id_to_index.items()}\n",
    "index_to_book_id = {idx: bid for bid, idx in book_id_to_index.items()}\n",
    "\n",
    "# Map ratings to indices\n",
    "ratings_filtered['user_index'] = ratings_filtered['user_id'].map(user_id_to_index)\n",
    "ratings_filtered['book_index'] = ratings_filtered['book_id'].map(book_id_to_index)\n",
    "\n",
    "# Create sparse user-item matrix (items × users)\n",
    "item_user_matrix = csr_matrix(\n",
    "    (ratings_filtered['rating'].astype(float),\n",
    "     (ratings_filtered['book_index'], ratings_filtered['user_index'])),\n",
    "    shape=(len(book_ids), len(user_ids))\n",
    ")\n",
    "\n",
    "print(f\"User-Item Matrix Shape: {item_user_matrix.shape} (books × users)\")\n",
    "print(f\"Non-zero elements: {item_user_matrix.nnz:,}\")\n",
    "print(f\"Sparsity: {(1 - item_user_matrix.nnz / (item_user_matrix.shape[0] * item_user_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Also create user-item matrix for recommendations\n",
    "user_items = csr_matrix(\n",
    "    (ratings_filtered['rating'].astype(float),\n",
    "     (ratings_filtered['user_index'], ratings_filtered['book_index'])),\n",
    "    shape=(len(user_ids), len(book_ids))\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Matrix preparation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II: Alternating Least Squares (ALS) Model\n",
    "\n",
    "### What Problem Does ALS Solve?\n",
    "\n",
    "ALS solves the **collaborative filtering problem**: predicting user preferences for items they haven't rated yet, based on:\n",
    "- Similar users' preferences\n",
    "- Similar items' characteristics\n",
    "- Latent patterns in the data\n",
    "\n",
    "### How Does ALS Use Matrix Factorization?\n",
    "\n",
    "ALS decomposes the user-item rating matrix **R** into two lower-rank matrices:\n",
    "\n",
    "**R ≈ U × V^T**\n",
    "\n",
    "Where:\n",
    "- **R**: Original user-item matrix (sparse, contains ratings)\n",
    "- **U**: User factor matrix (users × latent factors)\n",
    "- **V**: Item factor matrix (items × latent factors)\n",
    "- **Latent factors**: Hidden features (e.g., genre, writing style, complexity)\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. Initialize random user and item factors\n",
    "2. Iterate:\n",
    "   - Fix item factors, solve for user factors (least squares)\n",
    "   - Fix user factors, solve for item factors (least squares)\n",
    "3. Minimize: **||R - U × V^T||² + λ(||U||² + ||V||²)**\n",
    "\n",
    "### Main Hyperparameters\n",
    "\n",
    "- **factors**: Number of latent dimensions (default: 64)\n",
    "  - Higher = more expressive model, slower training, risk of overfitting\n",
    "  - Lower = faster training, less expressive\n",
    "\n",
    "- **regularization**: L2 penalty coefficient (default: 0.05)\n",
    "  - Higher = stronger regularization, simpler model, less overfitting\n",
    "  - Lower = weaker regularization, more complex model\n",
    "\n",
    "- **iterations**: Number of optimization passes (default: 20)\n",
    "  - Higher = better convergence, slower\n",
    "  - Lower = faster, may not converge\n",
    "\n",
    "- **alpha**: Confidence multiplier for implicit feedback (default: 2.0)\n",
    "  - Controls how much we trust observed ratings\n",
    "  - Higher = more trust in ratings\n",
    "\n",
    "### Recommender System Context\n",
    "\n",
    "For a new user, we:\n",
    "1. Compute their factor vector from their ratings\n",
    "2. Compute dot product with all item factors\n",
    "3. Rank items by predicted score\n",
    "4. Return top-N items not yet rated\n",
    "\n",
    "**Key Assumptions**:\n",
    "- User preferences can be represented by latent factors\n",
    "- Items have intrinsic characteristics (latent factors)\n",
    "- Rating = user affinity × item characteristics\n",
    "- Similar users have similar preferences\n",
    "- Similar items appeal to similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TASK II: TRAIN RECOMMENDATION MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK II: ALS MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize ALS Model\n",
    "print(\"\\n--- Initializing ALS Model ---\")\n",
    "\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=64,              # Number of latent dimensions\n",
    "    regularization=0.05,     # L2 regularization coefficient\n",
    "    iterations=20,           # Number of optimization iterations\n",
    "    alpha=2.0,              # Confidence multiplier\n",
    "    random_state=42,        # For reproducibility\n",
    "    use_gpu=False           # CPU-based training\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Parameters ---\")\n",
    "print(f\"Factors (latent dimensions): {model.factors}\")\n",
    "print(f\"Regularization: {model.regularization}\")\n",
    "print(f\"Iterations: {model.iterations}\")\n",
    "print(f\"Alpha (confidence): {model.alpha}\")\n",
    "\n",
    "print(\"\\nStarting ALS Model Training...\")\n",
    "print(\"This may take a few minutes depending on data size...\\n\")\n",
    "\n",
    "try:\n",
    "    model.fit(item_user_matrix, show_progress=True)\n",
    "    print(\"\\n✅ Model training complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during training: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- Learned Model Factors ---\")\n",
    "print(f\"User Factors Shape: {model.user_factors.shape}\")\n",
    "print(f\"Item Factors Shape: {model.item_factors.shape}\")\n",
    "\n",
    "print(\"\\n✅ ALS recommendation model ready!\")\n",
    "print(f\"   Latent dimensions: {model.factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GENERATING PERSONALIZED RECOMMENDATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING BOOK RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load book metadata\n",
    "print(\"\\nLoading book metadata...\")\n",
    "books_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv\"\n",
    "\n",
    "try:\n",
    "    books_df = pd.read_csv(books_url, usecols=['book_id', 'title'])\n",
    "    print(f\"✅ Loaded metadata for {len(books_df):,} books\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not load books.csv: {e}\")\n",
    "    print(\"Creating dummy book titles...\")\n",
    "    books_df = pd.DataFrame({\n",
    "        'book_id': list(index_to_book_id.values()),\n",
    "        'title': [f\"Book {bid}\" for bid in index_to_book_id.values()]\n",
    "    })\n",
    "\n",
    "# Function to get book title\n",
    "def get_book_title(book_index):\n",
    "    try:\n",
    "        original_book_id = index_to_book_id.get(book_index)\n",
    "        if original_book_id is None:\n",
    "            return f\"Book {book_index}\"\n",
    "        title = books_df[books_df['book_id'] == original_book_id]['title'].values\n",
    "        return title[0] if len(title) > 0 else f\"Book {original_book_id}\"\n",
    "    except:\n",
    "        return f\"Book {book_index}\"\n",
    "\n",
    "# Select a test user\n",
    "test_user_id = ratings_filtered['user_id'].iloc[0]\n",
    "test_user_index = user_id_to_index[test_user_id]\n",
    "\n",
    "print(f\"\\nGenerating recommendations for User ID {test_user_id} (index {test_user_index})\")\n",
    "\n",
    "# Generate recommendations\n",
    "# Extract the specific user's ratings row from the user_items matrix\n",
    "user_ratings_vector = user_items[test_user_index]\n",
    "\n",
    "recommendations, scores = model.recommend(\n",
    "    userid=test_user_index,\n",
    "    user_items=user_ratings_vector,\n",
    "    N=10,\n",
    "    filter_already_liked_items=True\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Top 10 Recommendations ---\")\n",
    "print(f\"{'Rank':<6} {'Book Title':<40} {'Score':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for rank, (book_idx, score) in enumerate(zip(recommendations, scores), 1):\n",
    "    title = get_book_title(book_idx)\n",
    "    print(f\"{rank:<6} {title:<40} {score:.4f}\")\n",
    "\n",
    "# Show user's previously rated books\n",
    "user_rated_books = ratings_filtered[ratings_filtered['user_id'] == test_user_id].sort_values('rating', ascending=False).head(5)\n",
    "\n",
    "print(f\"\\n--- Top 5 Books User {test_user_id} Has Already Rated ---\")\n",
    "print(f\"{'Book Title':<40} {'Rating':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for _, row in user_rated_books.iterrows():\n",
    "    book_idx = book_id_to_index[row['book_id']]\n",
    "    title = get_book_title(book_idx)\n",
    "    print(f\"{title:<40} {row['rating']:.0f}/5\")\n",
    "\n",
    "print(\"\\n✅ Recommendations generated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
